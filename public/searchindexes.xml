<?xml version="1.0" encoding="utf-8" standalone="yes"?><search><entry><title>掌握 JuiceFS：数据存储的基本单元</title><url>/post/distributed/juicefs-data-storage/</url><categories><category>分布式</category></categories><tags><tag>分布式文件系统</tag><tag>JuiceFS</tag></tags><content type="html"><![CDATA[  传统文件系统只能使用本地磁盘存储数据和对应的元数据，JuiceFS 会将数据格式化以后存储在对象存储，同时会将文件的元数据存储在元数据引擎，具有很好的扩展性，可以轻松处理大量数据和高并发访问。本文学习JuiceFS 文件系统的架构和它的Chunk、Slice 和 Block。
一、JuiceFS 的技术架构 JuiceFS 文件系统由三个部分组成：JuiceFS 客户端（Client）、数据存储（Data Storage）、元数据引擎（Metadata Engine）。
JuiceFS 客户端（Client）：所有文件读写，以及碎片合并、回收站文件过期删除等后台任务，均在客户端中发生。客户端需要同时与对象存储和元数据引擎打交道。客户端支持多种接入方式。 数据存储（Data Storage）：文件将会被切分上传至对象存储服务。JuiceFS 支持几乎所有的公有云对象存储，同时也支持 OpenStack Swift、Ceph、MinIO 等私有化的对象存储。 元数据引擎（Metadata Engine）：用于存储文件元数据（metadata）。 graph TD subgraph JuiceFS 客户端 [JuiceFS 客户端] G1[客户端] G1 --&gt;|文件读写| H1[对象存储] G1 --&gt;|元数据操作| I1[元数据引擎] end subgraph 接入方式 [接入方式] A1[FUSE] A2[Hadoop Java SDK] A3[Kubernetes CSI 驱动] A4[S3 网关] A5[WebDAV 服务] end A1 --&gt;|挂载到服务器| B1[POSIX 兼容] A2 --&gt;|替代 HDFS| C1[Hadoop] A3 --&gt;|提供海量存储| D1[Kubernetes] A4 --&gt;|直接接入| E1[S3 兼容应用] A5 --&gt;|HTTP 协议| F1[WebDAV 客户端] subgraph 数据存储 [数据存储] H1 --&gt; J1[公有云对象存储] H1 --&gt; J2[私有化对象存储] end subgraph 元数据引擎 [元数据引擎] I1 --&gt; N1[Redis] I1 --&gt; O1[TiKV] I1 --&gt; P1[MySQL/MariaDB] I1 --&gt; Q1[PostgreSQL] I1 --&gt; …  ]]></content></entry><entry><title>Golang的list和源码分析</title><url>/post/golang/list-sourcecode/</url><categories><category>Golang</category></categories><tags><tag>Golang</tag><tag>双向链表</tag><tag>源代码</tag></tags><content type="html">  刷力扣时，有这样一道题，要求设计并实现一个满足 LRU (最近最少使用) 缓存约束的数据结构，实现这道题用到了Go 官方库提供的container/list包中的List（双向链表）。
一、container/list的常用API Go语言中的container/list包提供了一个双向链表的实现，它适用于需要频繁插入和删除操作的场景。以下是container/list包中一些常用的API和操作方法：
创建链表 list.New()：创建一个新的双向链表。 添加元素 PushFront(v interface{}) *Element：在链表的前端插入一个新的元素，并返回该元素。 PushBack(v interface{}) *Element：在链表的后端插入一个新的元素，并返回该元素。 InsertBefore(v interface{}, mark *Element) *Element：在指定元素mark之前插入一个新的元素。 InsertAfter(v interface{}, mark *Element) *Element：在指定元素mark之后插入一个新的元素。 删除元素 Remove(e *Element) interface{}：从链表中移除元素e，并返回该元素的值。 遍历链表 Front() *Element：返回链表的第一个元素。 Back() *Element：返回链表的最后一个元素。 其他操作 Len() int：返回链表中元素的数量。 MoveToFront(e *Element)：将元素e移动到链表的前端。 MoveToBack(e *Element)：将元素e移动到链表的后端。 二、源码分析 Go 中container/list的相关部分可以在源码下的 src/container/list/list.go 查看。以下源代码基于 go1.23.3 版本，有删减。
2.1 Element 结构体 // Element is an element of a linked list. type Element struct { // Next and previous pointers in the doubly-linked list of elements. // To simplify the implementation, …  </content></entry><entry><title>Golang的channel和源码分析</title><url>/post/golang/channel-sourcecode/</url><categories><category>Golang</category></categories><tags><tag>Golang</tag><tag>源代码</tag></tags><content type="html">  channel 的底层结构是一个复杂的并发数据结构，包含了缓冲区、等待队列、互斥锁等组件，用于实现goroutine之间的安全通信和同步。
Go 语言中的 channel 底层是通过 hchan 结构体实现的，hchan 结构体的定义和相关操作都位于 runtime/chan.go 文件中，以下源代码基于 go1.23.3 版本，有删减。
一、channel 的底层结构 channel涉及到的核心数据结构包含3个，hchan、waitq、sudog。
1.1 hchan 以下是 hchan 结构体的定义：
type hchan struct { qcount uint // 当前 channel 中的数据个数 dataqsiz uint // channel 缓冲区的大小 buf unsafe.Pointer // 指向缓冲区的指针 elemsize uint16 // channel 中元素的大小 closed uint32 // channel 是否关闭的标志 elemtype *_type // channel 中元素的类型 sendx uint // 发送操作的索引 recvx uint // 接收操作的索引 recvq waitq // 接收操作的等待队列 sendq waitq // 发送操作的等待队列 lock mutex // 互斥锁，用于保护 channel 的操作 } hchan结构体的主要组成部分有四个：
buf：用来保存goroutine之间传递数据的循环链表。 sendx和recvx：用来记录此循环链表当前发送或接收数据的下标值。 sendq 和 recvq：用于保存向该chan发送和从该chan接收数据的goroutine的队列。 lock：保证channel写入和读取数据时线程安全的锁。 1.2 waitq waitq是因读写 channel 而陷入阻塞的协程等待队列。
type waitq struct { first *sudog // 队列头部 last *sudog // 队列尾部 } 1.3 sudog sudog是协程等待队列的节点。
type sudog struct { g *g // 等待send或recv的协程g next *sudog // 等待队列下一个结点next prev *sudog // 等待队列前一个结 …  </content></entry><entry><title>Golang的map扩容和源码分析</title><url>/post/golang/map-sourcecode/</url><categories><category>Golang</category></categories><tags><tag>Golang</tag><tag>源代码</tag></tags><content type="html">  Go 中的 map 是一种内置的数据结构，它实现了哈希表的特性，可以存储键值对。本篇文章学习map的底层结构和扩容机制。
map 的相关部分可以在源码下的 runtime/map.go 文件中查看，以下源代码基于 go1.23.3 版本，有删减。
一、map 的底层结构 Go 中的 map 在内存中主要涉及的结构有hmap和bmap。
每个 map 的底层结构是hmap，是有若干个结构为bmap的bucket组成的数组。每个bucket底层都采用链表结构。
1.1 hmap 结构体 它是 map 的核心结构体，包含了 map 的元数据和指向底层数据的指针。hmap 结构体中包含的字段有：
type hmap struct { count int // 表示 map 中存储的键值对数量。 flags uint8 // 用于存储 map 的一些标志位，如是否只读等。 B uint8 // 表示哈希表的桶数组的大小，具体来说，桶数组的大小为 2^B。 noverflow uint16 // 表示 map 中溢出桶的大致数量。 hash0 uint32 // 哈希种子，用于计算哈希值时的初始值，以避免哈希碰撞。 buckets unsafe.Pointer // 指向桶数组的指针，桶数组是存储键值对的直接容器。 oldbuckets unsafe.Pointer // 在扩容时使用，指向旧的桶数组。 nevacuate uintptr // 在扩容时使用，记录需要重新分配的桶的数量。 extra *mapextra // 额外记录overflow桶信息，不一定每个map都有 } // 额外记录overflow桶信息 type mapextra struct { overflow *[]*bmap oldoverflow *[]*bmap nextOverflow *bmap // 指向下一个可用overflow桶 } 1.2 bmap结构体 bmap 是 map 的底层数据结构之一，通常被称为桶（bucket）。每个 bmap 结构体可以存储最多 8 个键值对。以下是 bmap 结构体的主要组成部分：
type bmap struct { tophash [abi.MapBucketCount]uint8 } // 底层定义的常量 abi/map.go const ( …  </content></entry><entry><title>关于我</title><url>/about/</url><categories/><tags/><content type="html">  Hey，我是一只野鹿呀。
自2015年毕业后，我一直从事后端开发工作。是机缘巧合，也是命运使然，目标是一个又一个的十年之约。在这个瞬息万变的世界里，我对技术的热爱和追求始终不变。
我通过写博客记录自己的所见所思，若有不足之处，还请多多指教。
与世界交手的第N年，愿你我依旧保持热爱与勇气，仍兴味盎然，不畏岁月漫长。
技术栈 语言：熟悉 Golang、PHP，了解 Java、Python 中间件：MySQL、Redis、RabbitMQ、RocketMQ、Kafka、ES 云原生：K8s、Docker 系统：高并发、问题排查、性能优化   </content></entry><entry><title>MySQL B+树的层数计算</title><url>/post/db/mysql-b+tree-calculate/</url><categories><category>数据库</category></categories><tags><tag>MySQL</tag><tag>Tree</tag></tags><content type="html">  在MySQL中，当数据量达到千万级时，B+树通常有3层。本文学习如何计算InnoDB中一棵B+树可以存放的数据数，以及如何根据数据量推算出对应的层数。
节点存储结构 在计算机中磁盘存储数据最小单元是扇区，一个扇区的大小是512字节，而文件系统（例如XFS/EXT4）他的最小单元是块，一个块的大小是4k，而对于我们的InnoDB存储引擎也有自己的最小储存单元——页（Page），一个页的大小是16K。
InnoDB存储引擎的最小存储单元是页，页可以用于存放数据也可以用于存放键值+指针，在B+树中叶子节点存放数据，非叶子节点存放键值+指针。
索引组织表通过非叶子节点的二分查找法以及指针确定数据在哪个页中，进而在去数据页中查找到需要的数据。
容量计算 叶子节点：假设一行记录的数据大小为1k，InnoDB存储引擎的页大小默认为16k，那么一个叶子节点（即一个页）可以存储16条记录。 非叶子节点：假设主键ID为bigint类型，长度为8字节，指针大小在InnoDB源码中为6字节，这样一共14字节，一个页中能存放多少这样的单元，就代表有多少指针，即 16384/（8+6）=1170个指针。 层数计算 B+树的树高为1时，意味着所有数据都存储在根节点（同时也是叶子节点）上。此时，数据量的大小取决于根节点的容量，即根节点可以存储多少条记录。
当B+树高为2甚至更高时，存在一个根节点和若干个叶子节点，那么这棵B+树的存放总记录数为：根节点指针数*单个叶子节点记录行数。
一层B+树：InnoDB存储引擎的页大小默认为16KB，假设每条记录的大小为1KB，那么根节点可以存储16条记录。 两层B+树：根节点为非叶子节点，有1170个指针，每个指针指向一个叶子节点，每个叶子节点有16条记录，所以总共可以存放1170×16=18720条记录。 三层B+树：根节点为非叶子节点，有1170个指针，每个指针指向一个非叶子节点，这些非叶子节点又各有1170个指针指向叶子节点，每个叶子节点有16条记录，所以总共可以存放1170×1170×16=21902400条记录。 高扇出特性 B+树的节点扇出非常高，即每个节点包含的子节点数多。这使得B+树能够在较少的层数内存储大量数据，从而在千万级数据量时，通常只需要3层就能满足需求。
磁盘IO优化 B+树通过减少树的高度，降低了磁盘IO次数。在查找数据时，一次页的 …  </content></entry><entry><title>LSM-tree的数据结构</title><url>/post/db/lsm-tree-structure/</url><categories><category>数据库</category></categories><tags><tag>Tree</tag></tags><content type="html"><![CDATA[  学习 LSM-tree（Log-Structured Merge Tree）数据结构的原理、特性以及在数据库中的应用。
一、什么是 LSM-tree 名称：Log-Structured Merge Tree，日志结构合并树。 核心思想：硬盘的顺序写入速度比随机写入快很多，因此 LSM-tree 以仅追加的形式写入磁盘。 组成： Memtable：Memory Mutable Table，内存可变表，用于存储最近的写入操作。 SSTable：Sorted String Table，有序字符串表，是Memtable的持久化版本。 WAL：Write-Ahead Log，预写日志，用于确保数据的持久性。 二、LSM-tree 的数据写入 写入策略：LSM-tree采用“异地更新”策略，即更新数据时不会直接修改原记录，而是将新记录写入新的位置。 写入过程：数据首先写入WAL和Memtable，当Memtable达到一定大小后，会刷新到磁盘成为SSTable。 graph TD A[开始写操作] --&gt; B[记录到WAL] B --&gt; C[写入Memtable] C --&gt; D[是更新操作吗?] D -- 是 --&gt; E[在Memtable中更新数据] D -- 否 --&gt; F[在Memtable中插入新数据] E --&gt; G[Memtable达到阈值?] F --&gt; G G -- 是 --&gt; H[Memtable转为Immutable Memtable] G -- 否 --&gt; I[继续写操作] H --&gt; J[Minor Compaction] J --&gt; K[Immutable Memtable写入磁盘成为Level 0 SSTable] K --&gt; L[结束写操作] 以下是LSM-tree写数据的更新流程：
写操作流程 记录日志（WAL）：
所有写操作（包括插入、更新和删除）首先记录到预写日志（Write-Ahead Log, WAL）中。WAL确保数据的持久性和一致性，即使在系统崩溃的情况下，也可以通过WAL恢复数据.
写入Memtable：
数据从WAL写入到内存中的Memtable。Memtable通常使用有序数据结构（如跳表或红黑树）来存储数据，以便快速访问和保持数据有序.
如果是更新操作，LSM-tree会在Memtable中为该键值对创建一个新的版本，而不是 …  ]]></content></entry><entry><title>构建分布式任务调度系统（二）：系统设计与实现</title><url>/post/distributed/system-design/</url><categories><category>分布式</category></categories><tags><tag>分布式任务调度</tag></tags><content type="html">  一、什么是分布式任务调度 任务调度是指基于给定的时间点，给定的时间间隔或者给定执行次数自动的执行任务。分布式调度系统用于处理需要在多个服务器或计算节点上并行执行的复杂计算任务，提高任务调度的效率、可靠性和可扩展性。
二、分布式任务调度的关键点 分布式：平台需要是可以分布式部署的，各个节点之间可以无状态和无限的水平扩展； 任务调度：涉及到任务状态管理、任务调度请求的发送与接收、具体任务的分配、任务的具体执行； 配置中心：可以感知整个集群的状态、任务信息的注册。
三、分布式任务调度系统设计 3.1 高可用设计 Web模块 和 Server模块： 提供 无状态部署，使用 Nginx 或 Load Balancer 进行请求负载均衡。 Server 模块实现 主从切换 或 集群部署，避免单点故障。 注册中心： 使用分布式注册中心（如 etcd、Zookeeper 或 Consul）来保证注册中心自身的高可用性。 Scheduler模块： 支持 任务主备调度 和 Leader选举，避免任务调度中心单点失效。 3.2 任务执行可靠性 任务重试与失败处理： 设计 重试机制：支持任务失败后的重试（按时间间隔、次数、优先级等配置）。 死信队列（DLQ）：将重试失败的任务存储到专门的队列中，方便后续人工介入处理。 幂等性保证： 在任务下发和执行时，增加幂等性检查，防止任务被重复执行。 任务状态存储： 将任务执行的中间状态和结果持久化到存储（如 MySQL、PostgreSQL 或 Elasticsearch），确保任务状态可靠记录。 3.3 Worker 节点的动态管理 健康检查： Scheduler 通过心跳机制定时检测 Worker 节点的存活状态。 动态扩容与缩容： 支持 自动发现 和 自动注册 新增的 Worker 节点，动态调整任务分配。 结合集群监控，判断 Worker 负载，自动将任务从高负载节点迁移到低负载节点。 3.4 任务调度优化 调度策略：支持多种调度策略，包括： 轮询调度：任务平均分配给 Worker 节点。 最少负载调度：将任务分配给负载最低的 Worker 节点。 优先级调度：高优先级任务优先执行。 分片调度：将任务切分成多个小任务，并分发到多个 Worker。 任务分布式锁： 使用 Redis、etcd 或 Zookeeper 实现分布式锁，确保任务不会被 …  </content></entry><entry><title>构建分布式任务调度系统（一）：时间轮</title><url>/post/distributed/timing-wheel/</url><categories><category>分布式</category></categories><tags><tag>分布式任务调度</tag><tag>时间轮</tag></tags><content type="html">  时间轮（Timing Wheel）是一种高效的数据结构，用于管理定时任务或事件。在分布式任务调度系统等场景中经常可以看到时间轮的实现，以实现对大量定时任务的高效调度。
一、为什么用时间轮 相比传统的队列形式的调度器来说，时间轮能够批量高效的管理各种延时任务、周期任务、通知任务等等。
启动定时器 终止定时器 周期清算 n 的含义 无序列表定时器 O(1) O(1) O(n) 定时器数量 有序列表定时器 O(n) O(n) O(1) 定时器数量 定时器树 O(log n) O(log n) O(1) 定时器数量 简单的时间轮 O(1) O(1) O(1) 同一时间槽定时器数量 有序定时器列表的散列轮 O(1)，最坏为 O(n) O(1) O(1) 同一时间槽定时器数量 无序定时器列表的哈希轮 O(1) O(1) O(1)，最坏为 O(n) 同一时间槽定时器数量 分级时间轮 O(m) = O(1) O(1) O(1) ，最坏为 O(n) m 为层级数，n为定时器数量 上面的表格对比了传统的简单调度器与时间轮，时间轮的效率更高。
二、时间轮的实现方式 时间轮有几种不同的实现方式，每种方式都有其特定的应用场景和性能特点。
时间轮类型 特点 适用场景 简单时间轮 固定大小的数组，指针循环移动 定时任务数量较少，时间间隔较短的场景 有序时间轮 数组元素按到期时间排序 需要快速定位到期任务，但添加或删除任务可能需要重新排序 无序时间轮 数组元素不排序，到期时间作为任务的一部分存储 添加和删除任务时不需要重新排序，但查找到期任务可能需要遍历 分层时间轮 多个时间粒度不同的时间轮组成，每个时间轮负责不同时间范围的任务 任务到期时间跨度较大的场景 散列时间轮 使用哈希表存储定时任务，减少同一时间槽内任务的冲突 可以快速定位到期任务，但哈希表的维护可能增加复杂性 最小堆时间轮 使用最小堆存储定时任务，堆顶是最早到期的任务 需要快速访问最早到期任务的场景 红黑树时间轮 使用红黑树存储定时任务，有序性允许快速查找、添加和删除操作 需要频繁动态调整任务的场景 延迟队列时间轮 结合时间轮和延迟队列，使用时间轮管理延迟队列中的任务 需要处理大量短生命周期定时任务的场景 三、时间轮的处理流程 3.1 简单时间轮（Simple Timing Wheel） 简单时间轮通常包含一个固定大小的数组，每个数组元 …  </content></entry><entry><title>Golang的结构体标签与反射</title><url>/post/golang/tag-and-reflect/</url><categories><category>Golang</category></categories><tags><tag>Golang</tag><tag>反射</tag><tag>源代码</tag></tags><content type="html"><![CDATA[  一、结构体标签 结构体标签是附加在结构体字段上的小块元数据字符串，格式为 key:&amp;quot;value&amp;quot;，其中 key 是标签名，value 是标签的值。一个字段可以有多个标签，标签之间用空格分隔。
type User struct { Name string `json:&amp;#34;name&amp;#34; xml:&amp;#34;user_name&amp;#34;` Age int `json:&amp;#34;age&amp;#34; xml:&amp;#34;user_age&amp;#34;` } 在这个例子中，Name 和 Age 字段都有两个标签，分别用于JSON和XML的序列化
二、结构体标签的读取 要读取结构体字段的标签，可以使用reflect包中的Field方法获取结构体的字段，然后使用Tag方法获取标签字符串。
import ( &amp;#34;fmt&amp;#34; &amp;#34;reflect&amp;#34; ) type MyStruct struct { Name string `这是个名字标签` // 不推荐 id int `desc:&amp;#34;这是id标签&amp;#34; sort:&amp;#34;这个字段可以用来排序&amp;#34;` // 推荐使用key value的方式定义标签 } func main() { // 通过反射获取标签 m := MyStruct{&amp;#34;小明&amp;#34;, 1} r := reflect.TypeOf(m) for i := 0; i &amp;lt; r.NumField(); i++ { field := r.Field(i) tag := field.Tag fmt.Println(field.Name, &amp;#34;的标签-&amp;gt;&amp;#34;, tag) } } 输出的结果是：
Name 的标签-&amp;gt; id 的标签-&amp;gt; desc:&amp;#34;这是id标签&amp;#34; sort:&amp;#34;这个字段可以用来排序&amp;#34; Name字段的标签是&amp;quot;这是个名字标签&amp;quot;，但这个标签没有遵循key:&amp;quot;value&amp;quot;正确的格式，因此它不会被reflect包识别为有效的结构体标签。 id字段的标签是&amp;quot;desc:\&amp;quot;这是id标签\&amp;quot; sort:\&amp;quot;这个字段可以用来排序\&amp;quot;&amp;quot;，这是一个有效的结构体 …  ]]></content></entry><entry><title>Golang的heap和源码分析</title><url>/post/golang/heap-sourcecode/</url><categories><category>Golang</category></categories><tags><tag>Golang</tag><tag>优先队列</tag><tag>源代码</tag></tags><content type="html">  之前用Go实现延时队列，我使用了Go标准库中的container/heap接口来构建一个优先队列。为什么Go的container/heap接口可以实现一个优先队列呢？
这是因为Go的container/heap定义了一套完整的方法，使得任何实现了这些方法的数据结构都能够作为堆来使用。优先队列是堆的一种应用，它允许快速访问最高（或最低）优先级的元素。
一、container/heap介绍 以下是container/heap接口实现优先队列的关键点：
定义数据结构：首先，需要定义一个数据结构来存储堆中的元素。 实现heap.Interface：container/heap接口要求实现以下方法： Len()：返回堆中元素的数量。 Less(i, j int) bool：比较索引为 i 和 j 的两个元素，确定它们在堆中的顺序。 Swap(i, j int)：交换索引为 i 和 j 的两个元素。 Push(x interface{})：向堆中添加一个新元素。 Pop() interface{}：移除并返回堆中的最后一个元素，即优先级最高的元素。 初始化堆：使用heap.Init()函数初始化堆，确保堆的性质得到满足。 操作堆：通过heap.Push()和heap.Pop()来添加和移除元素，这些操作会保持堆的性质。 更新元素：如果需要更新堆中的元素，可以使用heap.Fix()来重新调整堆，确保堆的性质不被破坏。 利用container/heap接口的灵活性，可以根据具体需求实现不同类型的优先队列，例如最小堆或最大堆。通过实现Less方法，可以定义元素之间的比较逻辑，从而控制优先级队列的行为。例如，如果要实现一个最大堆，可以在Less方法中使用大于号（&amp;amp;gt;）来比较元素，使得优先级最高的元素总是在堆的顶部。
此外，container/heap还提供了一些辅助函数，如heap.Push, heap.Pop, heap.Remove, 和 heap.Fix，使用这些函数可以更容易地实现和维护优先队列。
二、heap源码剖析 Go 中heap的相关部分可以在源码下的 src/container/heap/heap.go 查看。以下源代码基于 go1.23.3 版本，有删减。
2.1 核心接口 type Interface interface { sort.Interface …  </content></entry><entry><title>Golang的Defer的用法</title><url>/post/golang/defer/</url><categories><category>Golang</category></categories><tags><tag>Golang</tag></tags><content type="html">  在Go语言中，defer定义为关键字， 在开发过程中使用非常高频，本文通过常见案例来学习defer的执行机制。
1. defer 的执行顺序是什么？ 示例代码：
func main() { defer fmt.Println(1) // 第1个声明 → 最后执行 defer fmt.Println(2) // 第2个声明 → 最后执行 defer fmt.Println(3) // 第3个声明 → 最后执行 } 输出：
3 2 1 解析：
defer通过栈结构实现，遵循后进先出（LIFO）的顺序执行。最后一个defer最先执行，第一个defer最后执行。
2. defer 的参数计算时机 示例代码：
func test() int { i := 0 defer fmt.Println(&amp;amp;#34;defer:&amp;amp;#34;, i) // 参数 i 的值在 defer 声明时确定 i++ return i } 输出：
defer: 0 解析：
defer的参数在声明时立即求值，而非等到函数退出时才计算。此时 i 的值是 0，后续的 i++ 不影响已声明的 defer。
3. defer 与闭包结合时的变量捕获 示例代码：
func test() { i := 0 defer func() { fmt.Println(i) }() // 闭包捕获当前变量 i 的引用 i++ } 输出：
1 解析：
闭包通过引用捕获变量，执行时获取的是变量的最终值。i 在 defer 后自增到 1，因此输出 1。
4. defer 如何影响返回值？ 示例1：命名返回值：
func test() (result int) { defer func() { result++ }() return 5 // 将 result 设为 5 → 执行 defer，result++ → 最终返回 6 } 返回结果：6
示例2：匿名返回值：
func test() int { i := 0 defer func() { i++ }() return i // 返回值在 return 时确定为 0，后续 i++ 不影响返回值 } 返回结果：0
解析：
若返回值命名，defer 可以修改它（因为直接操作返回值变量）。 若返回值匿名，defer 修改的是局部变量，不影响已确定的返回值。 5. defer 在循环中的 …  </content></entry><entry><title>Golang实现一个基于本地存储的延时队列</title><url>/post/mq/delayed-queue/</url><categories><category>消息队列</category></categories><tags><tag>消息队列</tag><tag>延时队列</tag></tags><content type="html">  一、什么是延迟队列 延迟队列是一种特殊的队列，其核心特点是队列中的消息或任务会被延迟一定时间后才能被消费或执行。这种队列广泛应用于需要延迟处理的场景，比如订单超时未支付自动取消、用户注册后一段时间未登录发送提醒等。
二、延迟队列的应用场景 电商平台订单处理：超过一定时间未支付的订单自动取消。 商品签收后自动确认：在一定时间未确认的情况下，系统自动确认收货。 用户提醒：在平台注册但一定时间内未登录的用户，发送短信提醒。 会议通知：预定会议后，在预定时间点前一定时间通知与会人员。 三、延迟队列和定时任务的区别 特性 延迟队列 定时任务 触发时间 没有固定的开始时间，而是依赖于某个事件触发后，再延迟一段时间执行任务 有明确的触发时间，通常是按照固定的时间周期执行。可以通过cron表达式来设定具体的执行时间 周期性 无周期性，通常是一次性任务 有周期性，可以设置为定期重复执行 任务数量 通常处理单个任务 一般会同时处理多个任务 实现方式 消息队列、专门的延迟队列实现 可以通过编程语言或框架提供的定时器功能实现，如Golang的Timer包 应用场景 订单超时自动取消、用户操作后的反馈提示 数据备份、日志清理等定期执行的任务 数据库压力 通常是内存队列操作，处理效率较高，不会直接给数据库带来压力 查表会给数据库带来较大的查询压力，尤其是当业务数据量较大时 时效性 可以更精确地控制任务的执行时间，适合对实效性要求较高的场景 由于执行时间的不确定性，可能无法满足对实效性要求较高的系统需求 分布式支持 更容易实现分布式支持，适合大规模和高可用性的需求 在分布式环境下可能需要额外的协调机制来保证任务的一致性，比如分布式锁 可靠性 可以实现更好的异常恢复机制，尤其是在使用持久化存储的情况下 可能在系统异常恢复后丢失任务状态，需要额外的机制来保证任务的恢复 四、Golang实现延时队列 实现一个基于本地存储的延时队列，可以通过以下步骤进行：
定义任务结构：首先定义一个任务结构体，包含任务的执行时间和具体的任务内容。 使用优先队列：利用Go的container/heap接口实现一个优先队列，用于管理任务。优先队列可以根据任务的执行时间来排序任务。 存储任务：将任务存储在优先队列中，以便根据执行时间顺序执行。 定时检查和执行：通过一个循环，定时检查当前时间与队列中最早任务的执行时间。如果当前 …  </content></entry><entry><title>任务系统的设计</title><url>/post/system/task-system/</url><categories><category>系统设计</category></categories><tags/><content type="html"><![CDATA[  一、背景 由于业务中引入了小队、队长、导师、服务经理等角色，如何合理地安排和考核几千名司服和上万名队长的工作，就成为了不小的挑战，任务系统应运而生。
任务系统通过接入各类事件，在不同的任务场景下将任务分配给不同的角色——司服、队长、导师等。一旦任务完成，系统通过消息队列（MQ）机制及时通知下游系统。在某些特定场景下，还会推送质检任务，并根据结果发放相应的奖励，以此激励团队成员，提高整体工作效率和质量。
二、现状 2.1 任务分类较多 根据正向牵引数据源（新司机首次在线，完成首单&amp;hellip;&amp;hellip;）、反向异常数据源（行程不安全、申诉&amp;hellip;..）将任务分为十几种类别，且分类随着业务的开展还会不断增加。
2.2 任务接入来源较多 不同场景会有其对应的行为事件，进而产生不同的任务，接入任务系统的业务方非常多。
三、系统设计 3.1 梳理业务流程 针对上面的任务，以及日后要接入的其他类任务，核心业务流程分为4部分：
事件接入：通过API/ES/MQ系统交互的方式，确定当前任务场景下，司机所对应的行为事件。 圈定人群：在某一类场景下，司机的行为事件也有多种多样，通过一定的业务规则，来筛选我们的目标人群。 绑定任务：筛选完目标人群后，通过组织架构以及相应的任务模板来生成任务。 任务流程：任务接收人在APP上完成相关任务。 以工单任务为例，任务时序图如下所示： sequenceDiagram participant 任务系统 participant 行为引擎 participant 人群服务 participant 导师 participant 驱动 opt 任务下发 任务系统-&gt;&gt;行为引擎: 人群规则 行为引擎-&gt;&gt;人群服务: 人群圈定 人群服务-&gt;&gt;行为引擎: MQ人群流 行为引擎-&gt;&gt;任务系统: 数据填充 end opt 任务绑定 任务系统-&gt;&gt;导师: 任务领取 导师-&gt;&gt;导师: 任务完成 导师-&gt;&gt;任务系统: 领取奖励 任务系统-&gt;&gt;驱动: 积分发放 驱动-&gt;&gt;任务系统: 同步成功 end opt 任务剔除 任务系统-&gt;&gt;行为引擎: 人群准出 行为引擎-&gt;&gt;任务系统: 任务剔除 end 3.2 核心模块划分 任务系统按模块逻辑可以分为4部分，任务生成、基础能力、同步模块。
3.2.1 任务生成 1.动态圈定人群：如上图场景1所示的任务。
当服务后台配 …  ]]></content></entry><entry><title>Golang的弱引用</title><url>/post/golang/weak-reference/</url><categories><category>Golang</category></categories><tags><tag>Golang</tag><tag>垃圾回收</tag></tags><content type="html">  在学习观察者模式的时候，看到观察者模式的实现方式之一有弱引用，所以专门学习了一下这个知识点。
一、什么是弱引用 弱引用是一种特殊的引用类型，它允许引用一个对象而不增加该对象的引用计数。这意味着，弱引用不会阻止垃圾回收器（GC）回收被引用的对象，即使该对象只被弱引用关联。
说人话就是：弱引用的对象在任何时候都可能被垃圾回收器回收。
二、弱引用的应用场景 弱引用在处理缓存、对象池、观察者模式等场景中非常有用。在这些应用场景中，我们通常需要一个数据结构能够动态地增减对象，同时不会让这些对象被垃圾回收机制所回收，弱引用正好能够满足这个需求。
三、弱引用在Go中存在吗 答案：存在。
四、弱引用在Go语言中具体是如何实现的 sync.Map：sync.Map与普通的map不同，它不会阻止其键的垃圾回收。这意味着，如果一个键没有其他强引用，它所引用的对象可以被垃圾回收器回收。sync.Map提供了Store、Load和Delete等方法来操作键值对，同时允许垃圾回收器回收不再需要的键值对。 sync.Pool：sync.Pool提供了一种对象池的机制，它允许对象在不被使用时被回收。sync.Pool中的对象是弱引用的，它们可以在内存不足时被垃圾回收器回收，这使得sync.Pool成为实现缓存时避免内存泄漏的有用工具。 reflect.WeaklyTypedPtr方法：Go语言在标准库中提供了一种弱引用的实现方式，即使用reflect包中的WeaklyTypedPtr方法。该方法接受一个interface{}类型的输入，并将其转换为弱引用。使用该方法可以创建一个不会增加对象引用计数的指针，同时也不会让该对象被垃圾回收机制所忽略，这使得开发者能够更加灵活地管理内存。 垃圾回收机制：Go语言的垃圾回收机制也与弱引用有关。垃圾回收器会标记所有可达的对象为活跃状态，而未被标记的对象将被清除。在这个过程中，如果一个对象只被弱引用，那么它可能会被垃圾回收器回收。 五、实现一个自定义的弱引用机制 在Go语言中实现一个自定义的弱引用机制，可以通过以下几种方式：
1. 使用sync.Map实现 sync.Map是Go语言中提供的一种并发安全的map，它允许键被垃圾回收，即使它们仍然被sync.Map引用。因此，可以用sync.Map来实现弱引用。
import &amp;amp;#34;sync&amp;amp;#34; var …  </content></entry><entry><title>Golang实现观察者模式（Observer Pattern）</title><url>/post/desiginpattern/observer-pattern/</url><categories><category>设计模式</category></categories><tags/><content type="html">  观察者模式是一种行为型设计模式，它定义了对象间的一种一对多的依赖关系，使得每当一个对象状态发生改变时，其相关依赖对象都会得到通知并自动更新。这种模式也被称为发布-订阅模式、模型-视图模式、源-监听器模式。
观察者模式的主要目的是解决一个对象状态改变时，如何自动通知其他依赖对象的问题，同时保持对象间的低耦合和高协作性。
在观察者模式中，包含以下几个关键角色：
主题（Subject）：也称为被观察者，是状态变化的核心对象，负责管理所有的观察者并通知它们。 具体主题（ConcreteSubject）：具体主题是主题类的子类，它通常包含有经常发生改变的数据，当它的状态发生改变时它向各个观察者发出通知。 观察者（Observer）：依赖于主题对象的变化，并作出响应。 具体观察者（ConcreteObserver）：在具体观察者中维护一个指向具体目标对象的引用，它存储具体观察者的相关状态，这些状态需要和具体目标的状态保持一致；它实现了在抽象观察者Observer中定义的update()方法。 一、使用场景 车辆追踪系统：车辆的位置和状态需要实时监测，并及时通知相关的监控中心或用户。 股票市场监控系统：股票价格变化可以作为主题，而投资者或交易员可以作为观察者。 GUI开发：按钮、复选框、滚动条等GUI组件可以作为主题，而窗口、文本框等可以作为观察者。 二、优点 降低耦合度：观察者模式通过定义对象之间的一对多依赖关系，使得主题对象和观察者对象之间解耦，提高了系统的灵活性和可维护性。 动态响应：在并发编程中，系统的状态可能随时发生变化，观察者模式允许观察者对象根据主题对象状态的变化动态调整自己的行为，非常适合事件驱动的系统。 易于扩展：在并发系统中，新的观察者可以很容易地添加到系统中，而不需要修改现有的代码，提高了系统的可扩展性。 异步通信：观察者模式支持异步通信，允许系统在不阻塞的情况下进行通信。 广播通信支持：观察者模式支持广播通信，可以实现多对多的交互，适用于需要通知多个对象的状态变化的场景。 所以观察者模式很适合在并发编程中使用，尤其是在需要处理多个对象之间通信和状态更新的场景中。
三、缺点 性能问题：如果一个被观察者对象有很多的直接和间接的观察者的话，将所有的观察者都通知到会花费很多时间。 循环依赖：如果观察者和观察目标间有循环依赖，可能导致系统崩溃。 四、实现方式 接口实 …  </content></entry><entry><title>13种缓存模式汇总</title><url>/post/cache/caching-patterns/</url><categories><category>缓存</category></categories><tags/><content type="html"><![CDATA[  学习和总结了13种缓存模式的优缺点、应用场景和工作流程。（汇总见底部的思维导图）
缓存模式 读取流程 更新流程 Cache-Aside（旁路缓存） 命中：返回缓存数据；未命中：从数据库加载数据并缓存后返回 先更新数据库，然后更新或删除缓存中的数据 Read-Through（透读缓存） 同上 同上 Write-Through（透写缓存） 同上 同上 Write-Through with Expiry（带过期的透写缓存） 同上 同上 Read-Write（读写缓存） 同上 同上 Write-Back/Write-Behind（写后缓存） 同上 写入数据到缓存，然后异步写入数据库 Write-Around（写绕过缓存） 同上 直接更新数据库，可选更新缓存 Lazy Write-Back（懒写后缓存） 同上 写入数据到缓存，缓存批量异步写数据库 Timed Write-Back（定时写后缓存） 同上 写入数据到缓存，缓存定时写入数据库 Write-Back with Coalescing（合并写后缓存） 同上 写入数据到缓存，缓存合并后写入数据库 Cache-Only（仅缓存） 命中：返回缓存数据；未命中：从缓存的其他节点尝试获取数据 更新缓存 Hybrid Cache（混合缓存） 读取流程和更新流程根据组合的具体缓存模式而定 读取流程和更新流程根据组合的具体缓存模式而定 Adaptive Caching（自适应缓存） 读取流程和更新流程根据访问模式动态调整缓存策略 读取流程和更新流程根据访问模式动态调整缓存策略 graph LR A[1. Cache-Aside 旁路缓存] --&gt;|定义| B_def[应用程序直接管理缓存的读取和写入] A --&gt;|优点| C_adv[灵活、减少数据库负载、简单易于实现] A --&gt;|缺点| D_dis[需要手动管理缓存、存在缓存一致性问题] A --&gt;|应用场景| E_sce[读取频繁但更新较少的数据] A --&gt;|读取流程| F_rd[命中：返回缓存数据
未命中：从数据库加载并缓存后返回] A --&gt;|更新流程| G_up[更新数据库后更新或删除缓存] A1[2. Read-Through 透读缓存] --&gt;|定义| H_def[缓存层自动管理数据的读取] A1 --&gt;|优点| I_adv[简化应用程序逻辑、减少数据库负担] A1 …  ]]></content></entry><entry><title>认识MQTT（三）：MQTT在业务中的应用</title><url>/post/mq/use-mqtt/</url><categories><category>消息队列</category></categories><tags/><content type="html">  我们的系统连接着车辆和用户两端，车辆的个性化配置数据上报到云端，又或者用户登录后的账户信息下发给车端，车辆与云端之间的数据传输都是通过MQTT网关来实现的。
网关作为网络中间连接器、协议转换器，负责将车辆终端、众多业务后台复杂的网络连接场景、业务交互场景进行聚类转发。
针对车端：MQTT网关实时、稳定的将车辆运行状态、用户交互等信息转发至对应后端业务平台，包括但不限于整车运行状态、零部件状态、用户操作指令等。 针对平台：MQTT网关实时、稳定的将业务平台数据下发至车辆终端，包括但不限于整车实时运行状态、操作指令、复杂的内容类交互等。 作为MQTT网关的调用方，我们给车端下发数据，经常会遇到车辆不在线，导致下发失败的情况，这样就会导致云端和车端数据不一致。除了重试机制外，我们还会采用以下几种方案保证数据的准确性。
交互逻辑设计：云端先不更新，车端主动上报后再更新。可以参见之前写的 车辆激活（扫码激活）的实现 。 使用时间戳作为版本号：服务端的数据库表增加一个时间戳字段，此时间戳为作为版本号下发给车端。 车端如果正常接收到云端下发的数据，就会与本地的版本号（时间戳）进行比对，接收到的时间戳大就更新。 车端如果没有接收到云端下发的数据，在上电的时候，会主动请求获取云端的数据，并携带这个版本号。云端会将其与记录进行比对，如果该时间戳大于记录的时间戳，说明是在车端进行的操作，以车端为主，更新表里的时间戳；反之云端会将数据重新下发给车端。 graph TD A[服务端] -->|增加时间戳字段| B[时间戳作为版本号] B --> C[下发给车端] C --> D[车端接收时间戳] D -->|比对本地版本号| E{时间戳比较} E -->|接收到的时间戳大| F[车端更新本地数据] E -->|接收到的时间戳小或相等| G[车端保持本地数据不变] H[车端] -->|上电| I[主动请求云端数据] I -->|携带本地时间戳| J[云端接收请求] J --> K[云端比对时间戳] K -->|车端时间戳大于云端| L[以车端数据为主] L --> M[更新云端数据库时间戳] K -->|车端时间戳小于等于云端| N[云端将数据下发给车端] M --> O[同步完成] N --> O   </content></entry><entry><title>Golang实现工厂模式（Factory Pattern）</title><url>/post/desiginpattern/factory-pattern/</url><categories><category>设计模式</category></categories><tags/><content type="html">  工厂模式（Factory Pattern）是一种创建型设计模式，用于处理对象的创建。在工厂模式中，创建对象的任务被推迟到子类中，这些子类被称为工厂方法。这种模式的主要目的是将对象的创建和使用分离，使得在不知道具体类的情况下也能创建对象。
一、使用场景 数据库连接：在应用程序中，可能需要连接不同类型的数据库（如MySQL、PostgreSQL等），每种数据库的连接方式可能不同。根据不同的数据库类型，创建相应的数据库连接对象。
日志记录器：在应用程序中，可能需要根据不同的环境（开发、测试、生产）使用不同的日志记录器。根据不同的环境，创建相应的日志记录器对象。
支付网关：电子商务平台可能需要支持多种支付方式（如PayPal、Stripe、信用卡等）。根据不同的支付方式，创建相应的支付处理对象。
二、优点 封装性：工厂模式隐藏了对象创建的细节，使得客户端代码只需要关心对象的接口，而不需要知道具体的实现类。
代码解耦：工厂模式将对象的创建和使用分离，降低了系统的耦合度，使得修改和扩展更加容易。
扩展性：当需要添加新的产品类时，只需要添加新的具体产品类和相应的工厂类，而不需要修改现有的代码，符合开闭原则。
代码重用：通过使用工厂模式，可以重用现有的代码来创建对象，而不需要每次都重新编写创建逻辑。
控制反转：对象的创建被委托给工厂类，而不是由客户端代码直接创建。
减少错误：由于对象的创建逻辑被封装在工厂类中，减少了在客户端代码中直接创建对象时可能发生的错误。
易于测试：工厂模式使得替换对象变得更加容易，因此在单元测试中可以轻松地使用mock对象。 三、缺点 增加复杂性和维护成本：因为需要额外的工厂类，尤其是当产品类的数量很多时，可能会增加系统的复杂性和维护成本。
可能违反单一职责原则：如果工厂类过于复杂，可能会违反单一职责原则，即一个类应该只有一个引起它变化的原因。
四、实现方式 简单工厂模式 工厂方法模式 抽象工厂模式 建造者模式 原型模式 单例工厂模式 定义 一个工厂类封装创建对象的逻辑。 定义创建对象的接口，由子类决定实例化哪个类。 提供一个接口用于创建一系列相关或依赖对象的家族。 分离复杂对象的构建和表示，通过指定的构建过程创建不同的表示。 使用原型实例指定创建对象的种类，通过拷贝这些原型创建新的对象。 确保一个类只有一个实例，并提供一个全局访问点。 优点 简单直观，易于 …  </content></entry><entry><title>认识MQTT（二）：RabbitMQ支持MQTT</title><url>/post/mq/rabbitmq-support-mqtt/</url><categories><category>消息队列</category></categories><tags><tag>消息队列</tag><tag>通信协议</tag></tags><content type="html"><![CDATA[  RabbitMQ是通过插件的形式支持MQTT协议的，使用时，需要在RabbitMQ集群上启用rabbitmq_mqtt插件。
一、如何配置RabbitMQ以支持MQTT的QoS级别 MQTT QoS级别在RabbitMQ中不需要特别的配置，因为rabbitmq_mqtt插件会自动处理QoS级别。MQTT客户端在发布消息时指定QoS级别，RabbitMQ会根据这个级别处理消息。
AMQP和MQTT的QoS映射：
MQTT QoS 0对应于“至多一次”的消息传递，AMQP中没有直接对应的QoS级别。 MQTT QoS 1对应于“至少一次”的消息传递，AMQP中可以通过消息确认机制实现。 MQTT QoS 2对应于“只有一次”的消息传递，AMQP中可以通过事务或具有唯一消息ID的队列实现。 graph LR A[1. 配置RabbitMQ以支持MQTT QoS] --&gt; B[启用MQTT插件] A --&gt; C[2. 配置持久化] A --&gt; D[3. 配置手动消息确认] A --&gt; E[4. 配置死信队列] A --&gt; F[5. 配置集群和高可用性] A --&gt; G[6. 配置TLS/SSL] B --&gt; B1[&#34;启用命令：rabbitmq-plugins enable rabbitmq_mqtt&#34;] C --&gt; C1[&#34;设置消息和队列持久化&#34;] D --&gt; D1[&#34;确保客户端确认消息&#34;] E --&gt; E1[&#34;配置DLX（死信交换机）&#34;] F --&gt; F1[&#34;跨多个节点部署RabbitMQ&#34;] G --&gt; G1[&#34;配置TLS/SSL以加密传输&#34;] 二、如何确保RabbitMQ中的MQTT消息不会被丢失 确保RabbitMQ中MQTT消息不丢失，需要综合考虑消息的持久性、网络通信的可靠性、消息确认机制等多个方面。
graph LR A[确保RabbitMQ中MQTT消息不丢失] A --&gt; B[1. 消息持久化] B --&gt; B1[&#34;持久化队列 - 队列持久化策略&#34;] B --&gt; B2[&#34;持久化消息 - 消息持久化标记&#34;] A --&gt; C[2. 网络通信的可靠性] C --&gt; C1[&#34;使用TLS/SSL - 加密传输层&#34;] A --&gt; D[3. 消息确认机制] D --&gt; D1[&#34;手动确认 - 消费者确认消息处理完成&#34;] A --&gt; E[4. 配置死信队列] E --&gt; …  ]]></content></entry><entry><title>认识MQTT（一）：MQTT是什么</title><url>/post/mq/mqtt-introduction/</url><categories><category>消息队列</category></categories><tags><tag>消息队列</tag><tag>通信协议</tag></tags><content type="html"><![CDATA[  和车打交道后，接触到了MQTT，第一次听到这个词时，我还疑心自己是不是听错了，问Leader是不是MQ，得到了“不是”的答复，遂有此文，总结一下我所了解的MQTT。
一、MQTT的应用场景 graph LR subgraph 车辆集群 A1[车辆1] A2[车辆2] A3[车辆3] end B[MQTT Broker] subgraph 服务器集群 C[业务服务器] D[TSP平台] E[终端应用] end A1 --&gt;|发布/订阅消息| B A2 --&gt;|发布/订阅消息| B A3 --&gt;|发布/订阅消息| B B --&gt;|发布/订阅消息| C B --&gt;|发布/订阅消息| D B --&gt;|发布/订阅消息| E MQTT在车联网中主要应用在以下几个方面：
车辆实时监控：通过MQTT协议，车辆可以实时将其位置、速度、状态等信息发布到一个或多个监控中心。监控中心可以订阅这些信息并进行实时监控和分析，以提供实时的车辆位置跟踪和监控。
车辆远程控制：通过MQTT协议，车辆可以接收来自远程控制中心的指令，并执行相应的操作，如开关车门、启动引擎、调整车辆参数等，这样可以实现远程监控和控制车辆的功能。
车辆数据采集与共享：通过MQTT协议，车辆可以将其传感器和系统收集到的数据发布到一个或多个数据中心。数据中心可以订阅这些数据，并进行分析和共享，以支持车辆管理、故障诊断、预测维护等功能。
车辆交互和通信：通过使用MQTT协议，车辆可以与其他车辆、交通设施和智能交通系统进行实时交互和通信。例如，车辆可以发布其位置和行驶意图，以提供给其他车辆和交通设施，从而实现车辆之间的协同行驶和交通流优化。
在数据传输、设备管理、远程控制和车辆间通信等方面，MQTT以轻量级、低能耗、开放性、可靠性、异步通信、灵活性和实时性等优势成为车联网领域理想的通信协议。
二、什么是MQTT 上面的应用场景中，可以看到MQTT是一个协议，而我们知道MQ是一个中间件，二者在定义上就有了区别。
MQTT（Message Queuing Telemetry Transport）：一种应用层的消息协议，独立于传输层协议，可以运行在TCP/TLS或UDP上。
MQ（Message Queue）：通常指消息队列，如RabbitMQ、ActiveMQ等，实现了特定的消息传递协议，如AMQP、STOMP等。
三、MQTT和MQ …  ]]></content></entry><entry><title>用Golang实现一个消息队列</title><url>/post/golang/implement-queue/</url><categories><category>Golang</category></categories><tags><tag>Golang</tag><tag>消息队列</tag></tags><content type="html"><![CDATA[  Go的channel是并发编程中的一种同步通信机制，天然支持并发请求，因此可以用来实现消息队列。这里实现一个能够处理并发请求的消息队列。
一、设计消息队列的基本结构 定义一个Message结构体来存储消息的ID和负载，一个Queue结构体来管理消息队列。
type Message struct { ID string Payload interface{} } type Queue struct { messages []Message mutex sync.Mutex cond *sync.Cond } func NewQueue() *Queue { q := &amp;Queue{} q.cond = sync.NewCond(&amp;q.mutex) return q } 二、实现生产者和消费者 生产者负责生成消息并将其添加到队列中，消费者从队列中读取消息并进行处理。为了确保线程安全和条件等待，可以使用sync.Mutex和sync.Cond。
func (q *Queue) Produce(msg Message) { q.mutex.Lock() defer q.mutex.Unlock() q.messages = append(q.messages, msg) q.cond.Signal() } func (q *Queue) Consume() Message { q.mutex.Lock() defer q.mutex.Unlock() for len(q.messages) == 0 { q.cond.Wait() } msg := q.messages[0] q.messages = q.messages[1:] return msg } 三、并发处理 使用goroutine可以实现并发生产和消费，用来模拟生产者和消费者的行为。
func main() { queue := NewQueue() // 生产者Goroutine go func() { for i := 0; i &lt; 10; i++ { msg := Message{ID: fmt.Sprintf(&#34;msg-%d&#34;, i), Payload: fmt.Sprintf(&#34;Data %d&#34;, i)} queue.Produce(msg) fmt.Printf(&#34;Produced: %v\n&#34;, msg) time.Sleep(time.Second) } }() // 消费者Goroutine go func() { for { msg := queue.Consume() fmt.Printf(&#34;Consumed: %v\n&#34;, msg) time.Sleep(time.Second * 2) } }() // 防止主程序退出 select {} } 四、持久化存储 将消息存储在磁盘或数据库中，防止系统崩溃导致数据丢失。
将消息写入到一个日志文件中，这样即使程序重启，消息也不会丢失。 在数据库中创建一个表来存储消息，并在消息处理失败时将消息插入到这个表中。   ]]></content></entry><entry><title>Golang实现单例模式（Singleton Pattern）</title><url>/post/desiginpattern/singleton-pattern/</url><categories><category>设计模式</category></categories><tags/><content type="html">  单例模式（Singleton Pattern）是一种常用的软件设计模式，其核心思想是确保一个类只有一个实例，并提供一个全局访问点来获取这个实例。这种模式在很多场景下都非常有用，特别是在需要控制资源访问的情况下。
一、使用场景 配置管理器：当配置信息被整个应用程序共享时，使用单例模式可以确保配置信息只被初始化一次。
连接池：数据库连接池通常使用单例模式，以确保整个应用程序中只有一个连接池实例。
日志记录器：日志记录器通常作为单例实现，以确保所有日志消息都发送到同一个日志文件或日志系统中。
硬件接口：如打印机、扫描仪等硬件设备的控制，通常只允许一个实例与硬件交互。
线程池：线程池管理线程的创建和销毁，使用单例模式可以避免创建过多的线程。 二、优点 节省资源：由于只创建一个实例，可以节省内存和系统资源。
控制访问：可以严格控制对实例的访问，确保实例的线程安全和数据的一致性。
简化代码：通过全局访问点，可以简化代码，避免在多个地方创建实例。
三、缺点 全局状态：单例模式创建了一个全局访问点，可能导致代码间的耦合性增加，使得代码维护和测试变得更加困难。
扩展性问题：单例模式的核心是全局只有一个实例。如果未来需要扩展为多个实例，或者需要支持多种类型的单例，单例模式可能需要重构。
单点故障：如果单例对象是系统中的关键组件，它的失败可能会导致整个系统的故障。
难以单元测试：单例模式的全局状态使得单元测试变得复杂，因为测试代码可能会相互干扰，或者需要在每个测试用例中重置单例状态。
四、实现方式 实现单例模式时，常见的有懒汉式（延迟加载）、饿汉式（预先加载）、双重检查锁定（Double-Checked Locking）等，这里主要用 Golang 来实现。
1. 懒汉式 懒汉式单例模式在第一次被使用时才创建实例。这种方式的好处是只有在需要时才创建实例，节省资源。缺点是每次访问都需要检查实例是否已经被创建，可能会影响性能。
此外，懒汉式在多线程环境下需要特别注意线程安全问题，比如，在多线程环境中，如果两个线程同时检查到实例未被创建，并且都去创建实例，就会创建多个实例，违反了单例模式的原则，于是就有了双重检查锁定的优化实现。
package singleton // Singleton 结构体定义 type Singleton struct{} // instance …  </content></entry><entry><title>车辆激活（扫码激活）的实现</title><url>/post/system/vehicle-active/</url><categories><category>系统设计</category></categories><tags/><content type="html"><![CDATA[  一、业务场景 车辆激活是在车端大屏幕上生成一个二维码，车主使用App进行扫码，点击“确认激活”，车端收到指令后，由相应的模块（一般是CDC）进行本地激活。
二、激活流程图 sequenceDiagram participant Car as 车端 participant Cloud as 云端 participant MQTT as MQTT网关 participant OwnerApp as 车主App Car-&gt;&gt;Cloud: 1.1 请求生成二维码ID Cloud-&gt;&gt;MQTT: 1.2 通过MQTT下发二维码ID MQTT-&gt;&gt;Car: 1.3 接收二维码ID Car-&gt;&gt;Car: 1.4 生成二维码并显示在大屏幕上 OwnerApp-&gt;&gt;Car: 2.1 扫描二维码，获取二维码ID OwnerApp-&gt;&gt;Cloud: 2.2 将二维码ID发给云端 Cloud-&gt;&gt;Cloud: 2.3 将二维码状态更新为“已扫描” OwnerApp-&gt;&gt;OwnerApp: 2.4 显示“确认激活”按钮 OwnerApp-&gt;&gt;Cloud: 3.1 点击“确认激活”，发送激活指令 Cloud-&gt;&gt;Cloud: 3.2 将二维码状态更新为“已确认” Cloud-&gt;&gt;MQTT: 3.3 通过MQTT下发激活指令 MQTT-&gt;&gt;Car: 3.4 下发激活指令 Car-&gt;&gt;Car: 4.1 车端CDC接收指令并进行本地激活 三、激活流程 3.1 车端生成二维码 该阶段是车端跟云端的交互过程。
用户提车后，打开车端大屏幕，发起激活请求，云端在接收到这一请求时，会生成一个唯一的二维码ID，并将该ID转化为Base64编码的字符串，通过MQTT下发给车端。 该二维码ID一定是唯一的，后续流程会将二维码ID跟车辆ID绑定，用于后续操作的校验。 车端会启动一个定时器，轮询查询二维码是否被扫描，如果未被App扫描，隔一段时间二维码会自动刷新。 3.2 App扫描二维码 该阶段是客户端跟云端的交互过程。
App扫描二维码，解析出二维码ID，将二维码ID作为参数发送给云端。 云端接到请求后，会通过二维码 ID 查找Redis缓存进行校验，校验通过后，将二维码状态更新为“已扫描”。 App接收到扫码请求成功的结果后，会跳转到激活页面，请车主在手机App端确认激活。 3.3 App确认激活 该阶段是客户 …  ]]></content></entry><entry><title>团队PK赛：分布式任务分片与数据一致性解决方案</title><url>/post/system/team-pk/</url><categories><category>系统设计</category></categories><tags><tag>任务分片</tag><tag>数据一致性</tag></tags><content type="html"><![CDATA[  团队PK赛是一种激励司机通过组织或自由报名形成小团队，并针对特定业务指标进行竞赛的活动。在满足基本入围条件后，城市会根据排名发放奖励。本文记录当时遇到的问题和解决方案。
挑战一：数据拉取与并行计算 问题描述：
排行榜需要从特征团队拉取数据，如果单机串行处理，面对大量活动时可能无法及时完成数据处理；单机并行处理又可能导致资源耗尽。因此，需要实现多机并行计算。
解决思路：
方案1：一致性哈希
通过Apollo或GetHosts获取当前机器列表，使用取模方式分配SQL查询，以拉取并处理数据。这需要考虑节点不可用的情况，可能需要引入探活组件。
方案2：分布式主从模型
使用多个Docker机，以Redis作为锁，选择一个master Docker机执行定时任务，通过Nginx负载均衡分配任务。
方案3：MQ任务分发
在方案2的基础上，需要一个主进程来推送任务，然后分发到MQ。使用拉模式，并使用ACK保障任务的已执行。
解决方案：方案3
使用定时任务从特征团队拉取数据，并通过MQ进行任务分发，实现并行计算。利用MQ拉取和ACK机制，确保消息的有效一次性处理，并控制消费速度。
sequenceDiagram participant Crontab participant 后台 participant MQ participant REDIS participant 特征团队 Crontab -&gt;&gt; 后台: 活动计算 (30min/次) 后台 -&gt;&gt; 后台: 待处理，活动列表 后台 -&gt;&gt; MQ: 活动分片 (活动ID+团队ID+版本号) MQ -&gt;&gt; MQ: 消息推送 MQ -&gt;&gt; 后台: MQ消息（sdk拉） 后台 -&gt;&gt; 后台: 解析活动分片 后台 -&gt;&gt; REDIS: 获取分片版本数据 REDIS -&gt;&gt; REDIS: 版本是否存在？ alt 版本存在 REDIS -&gt;&gt; MQ: ACK end alt 版本不存在 后台 -&gt;&gt; 后台: 获取分片成员 后台 -&gt;&gt; 特征团队: 获取所有成员版本数据 特征团队 -&gt;&gt; 特征团队: 计算分片指标 特征团队 --&gt;&gt; REDIS: 返回数据 end REDIS -&gt;&gt; REDIS: 版本是否存在？ alt 版本存在 REDIS -&gt;&gt; MQ: ACK end alt 版本不存在 REDIS -&gt;&gt; REDIS: …  ]]></content></entry><entry><title>Golang的定时器之Time.Ticker</title><url>/post/golang/time-ticker/</url><categories><category>Golang</category></categories><tags><tag>Golang</tag></tags><content type="html"><![CDATA[  一、引子 面试官问了一道题：每秒钟调用一次proc并保证程序不退出。
package main func main() { } func proc() { panic(&amp;#34;ok&amp;#34;) } 这道题考察的知识点主要有：
定时执行任务 捕获 panic 错误 这里主要学习、了解 Time.Ticker 的实现，其源代码基于 Go 1.17.9 版本，主要在 src/time/tick.go 文件中，包含了一个结构体和四个函数。
二、Time.Ticker Ticker 是一个周期触发定时的计时器，它会按照一个时间间隔往 channel 发送系统当前时间，而 channel 的接收者可以以固定的时间间隔从 channel 中读取事件。
2.1 结构体 type Ticker struct { C &amp;lt;-chan Time // The channel on which the ticks are delivered. r runtimeTimer } //注：该结构体在src/time/sleep.go中 type runtimeTimer struct { pp uintptr when int64 period int64 f func(any, uintptr) // NOTE: must not be closure arg any seq uintptr nextwhen int64 status uint32 } 可以看到这个结构体包含了一个只读的通道 C，并每隔一段时间向其传递&amp;quot;tick&amp;quot;。
2.2 NewTicker() NewTicker() 主要包含两步：
创建一个 Ticker，主要包括其中的 C 属性和 r 属性。r 属性是 runtimeTimer 类型。
调用 startTimer 函数，启动 Ticker。
如果 d &amp;lt;= 0 会 panic。
func NewTicker(d Duration) *Ticker { if d &amp;lt;= 0 { panic(errors.New(&amp;#34;non-positive interval for NewTicker&amp;#34;)) } c := make(chan Time, 1) t := &amp;amp;Ticker{ C: c, r: …  ]]></content></entry><entry><title>Golang的WaitGroup源码分析</title><url>/post/golang/waitgroup-sourcecode/</url><categories><category>Golang</category></categories><tags><tag>Golang</tag><tag>源代码</tag></tags><content type="html">  WaitGroup 是开发中经常用到的并发控制手段，其源代码在 src/sync/waitgroup.go 文件中，定义了 1 个结构体和 4 个方法：
WaitGroup{}：结构体。 state()：内部方法，在 Add()、Wait() 中调用。 Add()：添加任务数、改变任务数。 Done()：完成任务，其实就是 Add(-1)。 Wait()：阻塞等待所有任务的完成。 以下源代码基于 Go 1.17.5 版本，有删减。
$ go version go version go1.17.5 darwin/amd64 在学习之前可以先了解一些概念：
结构体对齐相关的内容，可参考 之前的笔记 。 信号量函数有两个： runtime_Semacquire 表示增加一个信号量，并挂起当前 goroutine。在 Wait() 里用到。 runtime_Semrelease 表示减少一个信号量，并唤醒 sema 上其中一个正在等待的 goroutine。在 Add() 里用到。 unsafe.Pointer 用于各种指针相互转换； uintptr 是 golang 的内置类型，能存储指针的整型，其底层类型是 int，可以和 unsafe.Pointer 相互转换。 一、结构体 1.1 state1 数组的组成 type WaitGroup struct { // 表示 `WaitGroup` 是不可复制的，只能用指针传递，保证全局唯一。 noCopy noCopy // state1 = state（*unit64） + sema（*unit32） // state = counter + waiter state1 [3]uint32 } state1 是一个 uint32 数组，包含了counter 总数、waiter 等待数 和 sema 信号量，其中：
counter：通过 Add() 设置的子 goroutine 的计数值。 waiter：通过 Wait() 陷入阻塞的 waiter 数。 sema：信号量。 1.2 state 和 sema 的位置 实际上，counter 和 waiter 合在一起，当成一个 64 位的整数来使用，所以 state1 数组又可以看成由 *unit64 的 state 和 *unit32 的 sema 组成，即：
state1 …  </content></entry><entry><title>Golang的Select的用法</title><url>/post/golang/select/</url><categories><category>Golang</category></categories><tags><tag>Golang</tag></tags><content type="html"><![CDATA[  Go 的通道有两种操作方式，一种是带 range 子句的 for 语句，另一种则是 select 语句，它是专门为了操作通道而存在的。这里主要介绍 select 的用法。
一、select的语法 select 语句的语法如下：
select { case &amp;lt;-ch1 : statement(s) case ch2 &amp;lt;- 1 : statement(s) … default : /* 可选 */ statement(s) } 这里要注意：
每个 case 都必须是一个通信。 由于 select 语句是专为通道设计的，所以每个 case 表达式中都只能包含操作通道的表达式，比如接收表达式。 如果有多个 case 都可以运行，select 会随机公平地选出一个执行，其他不会执行。 如果多个 case 都不能运行，若有 default 子句，则执行该语句，反之，select 将阻塞，直到某个 case 可以运行。 所有 channel 表达式都会被求值。 用一个简单示例看一下：
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;math/rand&amp;#34; ) func main() { // 准备好几个通道。 intChannels := [5]chan int{ make(chan int, 1), make(chan int, 1), make(chan int, 1), make(chan int, 1), make(chan int, 1) } // 随机选择一个通道，并向它发送元素值。 index := rand.Intn(5) fmt.Printf(&amp;#34;The index: %d\n&amp;#34;, index) intChannels[index] &amp;lt;- index // 哪一个通道中有可取的元素值，哪个对应的分支就会被执行。 select { case &amp;lt;-intChannels[0]: fmt.Println(&amp;#34;The first candidate case is selected.&amp;#34;) case &amp;lt;-intChannels[1]: fmt.Println(&amp;#34;The second candidate case is selected.&amp;#34;) case elem …  ]]></content></entry><entry><title>Golang的Channel发送和接收</title><url>/post/golang/channel/</url><categories><category>Golang</category></categories><tags><tag>Golang</tag><tag>源代码</tag></tags><content type="html"><![CDATA[  先来看一道面试题：
对已经关闭的 chan 进行读写，会怎么样？为什么？ 在上一篇学习 Go 协程的文章中，知道 go 关键字可以用来开启一个 goroutine 进行任务处理，但多个任务之间如果需要通信，就需要用到通道（channel）了。
一、Channel的定义 声明并初始化一个通道，可以使用 Go 语言的内建函数 make，同时指定该通道类型的元素类型，下面声明了一个 chan int 类型的 channel:
ch := make(chan int) 二、Channel的操作 发送（写）：发送操作包括了“复制元素值”和“放置副本到通道内部”这两个步骤。即：进入通道的并不是操作符右边的那个元素值，而是它的副本。
ch := make(chan int) // write to channel ch &amp;lt;- x 接收（读）：接收操作包含了“复制通道内的元素值”、“放置副本到接收方”、“删掉原值”三个步骤。
ch := make(chan int) // read from channel x &amp;lt;- ch // another way to read x = &amp;lt;- ch 关闭：关闭 channel 会产生一个广播机制，所有向 channel 读取消息的 goroutine 都会收到消息。
ch := make(chan int) close(ch) 从一个已关闭的 channel 中读取消息永远不会阻塞，并且会返回一个为 false 的 ok-idiom，可以用它来判断 channel 是否关闭：
v, ok := &amp;lt;-ch 如果 ok 是false，表明接收的 v 是产生的零值，这个 channel 被关闭了或者为空。
三、Channel发送和接收操作的特点 一个通道相当于一个先进先出（FIFO）的队列：也就是说，通道中的各个元素值都是严格地按照发送的顺序排列的，先被发送通道的元素值一定会先被接收。
对于同一个通道，发送操作之间和接收操作之间是互斥的：同一时刻，对同一通道发送多个元素，直到这个元素值被完全复制进该通道之后，其他针对该通道的发送操作才可能被执行。接收也是如此。
发送操作和接收操作中，对元素值的处理是不可分割的：前面我们知道发送一个值到通道，是先复制值，再将该副本移动到通道内部，“不可分割”指的是发送操作要么还没复制元素值，要 …  ]]></content></entry><entry><title>Golang的Waitgroup和锁</title><url>/post/golang/waitgroup/</url><categories><category>Golang</category></categories><tags><tag>Golang</tag></tags><content type="html"><![CDATA[  学 Go 的时候知道 Go 语言支持并发，最简单的方法是通过 go 关键字开启 goroutine 即可。可在工作中，用的是 sync 包的 WaitGroup，然而这样还不够，当多个 goroutine 同时访问一个变量时，还要考虑如何保证这些 goroutine 之间不会相互影响，这就又使用到了 sync 的 Mutex。
一、Goroutinue 先说 goroutine，我们都知道它是 Go 中的轻量级线程。Go 程序从 main 包的 main() 函数开始，在程序启动时，Go 程序就会为 main() 函数创建一个默认的 goroutine。使用 goroutine，使用关键字 go 即可。
package main import ( &amp;#34;fmt&amp;#34; ) func main() { // 并发执行程序 go running() } func running() { fmt.Println(&amp;#34;Goroutine&amp;#34;) } 执行代码会发现没有我们预期的“Goroutine”输出，这是因为当前的程序是一个单线程的程序，main 函数只要执行后，就不会再管其他线程在做什么事情，程序就自动退出了。解决办法是加一个 sleep 函数，让 main 函数等待 running 函数执行完毕后再退出。我们假设 running 函数里的代码执行需要 2 秒，因此让 main 函数等待 3 秒再退出。
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;time&amp;#34; ) func main() { // 并发执行程序 go running() time.Sleep(3 * time.Second) } func running() { fmt.Println(&amp;#34;Goroutine&amp;#34;) } 再次执行代码，终端输出了我们想要的“Goroutine”字符串。
二、WaitGroup 上面我们是假设了 running 函数执行需要 2 秒，可如果执行需要 10 秒甚至更长时间，不知道 goroutin 什么时候结束，难道还要 main 函数 sleep 更多的秒数吗？就不能让 running 函数执行完去通知 main 函数，main 函数收到信号自动退出吗？还真可以！可以使用 sync …  ]]></content></entry><entry><title>归档</title><url>/archives/archives/</url><categories/><tags/><content type="html">    </content></entry></search>